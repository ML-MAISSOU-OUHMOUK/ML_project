{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import csv\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np \n",
    "from time import time\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns \n",
    "from matplotlib import rcParams \n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "import math\n",
    "import pickle\n",
    "import os\n",
    "import networkx as nx\n",
    "import pdb\n",
    "from pandas import HDFStore,DataFrame\n",
    "from pandas import read_hdf\n",
    "from scipy.sparse.linalg import svds, eigs\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import xgboost as xgb\n",
    "import random\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 6552\n",
      "Number of edges: 12109\n",
      "Average in degree:   1.8481\n",
      "Average out degree:   1.8481\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('train_data.csv'):\n",
    "    train_graph=nx.read_edgelist('train_data.csv',delimiter=',',create_using=nx.DiGraph())\n",
    "    print(nx.info(train_graph))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.page rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = nx.pagerank(train_graph, alpha=0.85)\n",
    "pickle.dump(pr,open('page_rank.p','wb'))\n",
    "mean_pr=float(sum(pr.values())) / len(pr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.shortest path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_shortest_path_length(a,b):\n",
    "    p=-1\n",
    "    try:\n",
    "        if train_graph.has_edge(a,b):\n",
    "            train_graph.remove_edge(a,b)\n",
    "            p= nx.shortest_path_length(train_graph,source=a,target=b)\n",
    "            train_graph.add_edge(a,b)\n",
    "        else:\n",
    "            p= nx.shortest_path_length(train_graph,source=a,target=b)\n",
    "        return p\n",
    "    except:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3.Weakly connected components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcc=list(nx.weakly_connected_components(train_graph))\n",
    "def belongs_to_same_wcc(a,b):\n",
    "    index = []\n",
    "    if train_graph.has_edge(b,a):\n",
    "        return 1\n",
    "    if train_graph.has_edge(a,b):\n",
    "            for i in wcc:\n",
    "                if a in i:\n",
    "                    index= i\n",
    "                    break\n",
    "            if (b in index):\n",
    "                train_graph.remove_edge(a,b)\n",
    "                if compute_shortest_path_length(a,b)==-1:\n",
    "                    train_graph.add_edge(a,b)\n",
    "                    return 0\n",
    "                else:\n",
    "                    train_graph.add_edge(a,b)\n",
    "                    return 1\n",
    "            else:\n",
    "                return 0\n",
    "    else:\n",
    "            for i in wcc:\n",
    "                if a in i:\n",
    "                    index= i\n",
    "                    break\n",
    "            if(b in index):\n",
    "                return 1\n",
    "            else:\n",
    "                return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4.Adar Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_adar_in(x,y):\n",
    "    sum=0\n",
    "    try:\n",
    "        n=list(set(train_graph.successors(a)).intersection(set(train_graph.successors(b))))\n",
    "        if len(n)!=0:\n",
    "            for i in n:\n",
    "                sum=sum+(1/np.log10(len(list(train_graph.predecessors(i)))))\n",
    "            return sum\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5.Katz Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0.012338187799665829\n"
     ]
    }
   ],
   "source": [
    "katz = nx.katz.katz_centrality(train_graph,alpha=0.005,beta=1)\n",
    "pickle.dump(katz,open('katz.p','wb'))\n",
    "mean_katz= 0.012338187799665829\n",
    "print('mean',float(sum(katz.values())) / len(katz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6.HITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = nx.hits(train_graph, max_iter=100, tol=1e-08, nstart=None, normalized=True)\n",
    "pickle.dump(hits,open('hits.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"train_final.csv\"\n",
    "#number of elements\n",
    "n_train = sum(1 for line in open(filename)) \n",
    "s = 12110 # sample size\n",
    "skip_train = sorted(random.sample(range(1,n_train+1),n_train-s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"test_final.csv\"\n",
    "#number of elements\n",
    "n_test = sum(1 for line in open(filename))\n",
    "s = 3028 # sample size\n",
    "skip_test = sorted(random.sample(range(1,n_test+1),n_test-s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the train data file: 24220\n",
      "Number of rows we are going to elimiate in train data are 12110\n",
      "Number of rows in the test data file: 6056\n",
      "Number of rows we are going to elimiate in test data are 3028\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows in the train data file:\", n_train)\n",
    "print(\"Number of rows we are going to elimiate in train data are\",len(skip_train))\n",
    "print(\"Number of rows in the test data file:\", n_test)\n",
    "print(\"Number of rows we are going to elimiate in test data are\",len(skip_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our train matrix size  (12110, 3)\n"
     ]
    }
   ],
   "source": [
    "df_final_train = pd.read_csv('train_final.csv', skiprows=skip_train, names=['drug', 'protein'])\n",
    "df_final_train['indice'] = pd.read_csv('train_y.csv', skiprows=skip_train, names=['indice'])\n",
    "print(\"Our train matrix size \",df_final_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our test matrix size  (3029, 3)\n"
     ]
    }
   ],
   "source": [
    "df_final_test = pd.read_csv('test_final.csv', skiprows=skip_test, names=['drug', 'protein'])\n",
    "df_final_test['indice'] = pd.read_csv('test_y.csv', skiprows=skip_test, names=['indice'])\n",
    "print(\"Our test matrix size \",df_final_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug</th>\n",
       "      <th>protein</th>\n",
       "      <th>indice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DB00184</td>\n",
       "      <td>P05181</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>DB06637</td>\n",
       "      <td>Q9NZV8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>DB00201</td>\n",
       "      <td>Q01064</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>DB00141</td>\n",
       "      <td>Q9UJ70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>DB00454</td>\n",
       "      <td>P10635</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>DB01291</td>\n",
       "      <td>P08588</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>DB00818</td>\n",
       "      <td>P47870</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      drug protein  indice\n",
       "0  DB00184  P05181       1\n",
       "1  DB06637  Q9NZV8       1\n",
       "2  DB00201  Q01064       1\n",
       "3  DB00141  Q9UJ70       1\n",
       "4  DB00454  P10635       1\n",
       "5  DB01291  P08588       1\n",
       "6  DB00818  P47870       1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_train.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug</th>\n",
       "      <th>protein</th>\n",
       "      <th>indice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DB00421</td>\n",
       "      <td>P06401</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>DB00175</td>\n",
       "      <td>P08684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>DB01101</td>\n",
       "      <td>Q12882</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>DB06144</td>\n",
       "      <td>P50406</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>DB00590</td>\n",
       "      <td>P35348</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>DB02058</td>\n",
       "      <td>P21802</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>DB00731</td>\n",
       "      <td>P20815</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      drug protein  indice\n",
       "0  DB00421  P06401       1\n",
       "1  DB00175  P08684       1\n",
       "2  DB01101  Q12882       1\n",
       "3  DB06144  P50406       1\n",
       "4  DB00590  P35348       1\n",
       "5  DB02058  P21802       1\n",
       "6  DB00731  P20815       1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_test.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"page_rank.p\",\"rb\")\n",
    "file1 = open(\"hits.p\",\"rb\")\n",
    "file2 = open(\"katz.p\",\"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = pickle.load(file)\n",
    "katz = pickle.load(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#page rank for source and destination in Train and Test\n",
    "#if anything not there in train graph then adding mean page rank \n",
    "df_final_train['page_rank_s'] = df_final_train.drug.apply(lambda x:pr.get(x,mean_pr))\n",
    "df_final_train['page_rank_d'] = df_final_train.protein.apply(lambda x:pr.get(x,mean_pr))\n",
    "\n",
    "df_final_test['page_rank_s'] = df_final_test.drug.apply(lambda x:pr.get(x,mean_pr))\n",
    "df_final_test['page_rank_d'] = df_final_test.protein.apply(lambda x:pr.get(x,mean_pr))\n",
    "    \n",
    "#================================================================================\n",
    "#mapping adar index on train\n",
    "df_final_train['adar_index'] = df_final_train.apply(lambda row: calc_adar_in(row['drug'],row['protein']),axis=1)\n",
    "#mapping adar index on test\n",
    "df_final_test['adar_index'] = df_final_test.apply(lambda row: calc_adar_in(row['drug'],row['protein']),axis=1)\n",
    "\n",
    "#================================================================================\n",
    "#mapping same component of wcc or not on train\n",
    "df_final_train['same_comp'] = df_final_train.apply(lambda row: belongs_to_same_wcc(row['drug'],row['protein']),axis=1)\n",
    "\n",
    "##mapping same component of wcc or not on train\n",
    "df_final_test['same_comp'] = df_final_test.apply(lambda row: belongs_to_same_wcc(row['drug'],row['protein']),axis=1)\n",
    "\n",
    "#================================================================================\n",
    "#mapping shortest path on train \n",
    "df_final_train['shortest_path'] = df_final_train.apply(lambda row: compute_shortest_path_length(row['drug'],row['protein']),axis=1)\n",
    "#mapping shortest path on test\n",
    "df_final_test['shortest_path'] = df_final_test.apply(lambda row: compute_shortest_path_length(row['drug'],row['protein']),axis=1)\n",
    "#================================================================================\n",
    "\n",
    "#Katz centrality score for source and destination in Train and test\n",
    "#if anything not there in train graph then adding mean katz score\n",
    "df_final_train['katz_s'] = df_final_train.drug.apply(lambda x: katz.get(x,mean_katz))\n",
    "df_final_train['katz_d'] = df_final_train.protein.apply(lambda x: katz.get(x,mean_katz))\n",
    "\n",
    "df_final_test['katz_s'] = df_final_test.drug.apply(lambda x: katz.get(x,mean_katz))\n",
    "df_final_test['katz_d'] = df_final_test.protein.apply(lambda x: katz.get(x,mean_katz))\n",
    "#================================================================================\n",
    "\n",
    "#Hits algorithm score for source and destination in Train and test\n",
    "#if anything not there in train graph then adding 0\n",
    "df_final_train['hubs_s'] = df_final_train.drug.apply(lambda x: hits[0].get(x,0))\n",
    "df_final_train['hubs_d'] = df_final_train.protein.apply(lambda x: hits[0].get(x,0))\n",
    "\n",
    "df_final_test['hubs_s'] = df_final_test.drug.apply(lambda x: hits[0].get(x,0))\n",
    "df_final_test['hubs_d'] = df_final_test.protein.apply(lambda x: hits[0].get(x,0))\n",
    "#-------------------------------------------------------------------------------\n",
    "df_final_train['authorities_s'] = df_final_train.drug.apply(lambda x: hits[1].get(x,0))\n",
    "df_final_train['authorities_d'] = df_final_train.protein.apply(lambda x: hits[1].get(x,0))\n",
    "\n",
    "df_final_test['authorities_s'] = df_final_test.drug.apply(lambda x: hits[1].get(x,0))\n",
    "df_final_test['authorities_d'] = df_final_test.protein.apply(lambda x: hits[1].get(x,0))\n",
    "\n",
    "#================================================================================\n",
    "\n",
    "#saving the feature in 'Features.h5'\n",
    "hdf = HDFStore('Features.h5')\n",
    "hdf.put('train_df',df_final_train, format='table', data_columns=True)\n",
    "hdf.put('test_df',df_final_test, format='table', data_columns=True)\n",
    "hdf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
